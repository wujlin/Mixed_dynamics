{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05: Annotation Pipeline (LLM 标注流程)\n",
    "\n",
    "步骤：加载话题数据 → 预处理/过滤 → （可选）调用 LLM 标注情绪/风险 → 保存结果并汇总统计。\n",
    "\n",
    "**重要说明（避免口径混乱）**：\n",
    "- 本 notebook 主要用于 **连通性测试/小批量标注演示**，默认只抽样少量文本，避免误触发全量标注。\n",
    "- 项目正式分析请以 `outputs/annotations/master/long_covid_annotations_master.jsonl` 为唯一事实来源（master）。\n",
    "- 若要跑批量/全量标注，建议使用 `scripts/run_new_annotation.py` + `scripts/merge_new_annotations.py` 的流水线，而不是在 notebook 里长时间跑循环。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 路径与导入设置：确保能找到 src 模块\n",
    "ROOT = Path('..').resolve()  # notebook 位于 notebooks/ 下\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from src.empirical import (\n",
    "    LLMAnnotator,\n",
    "    load_topic_dataset,\n",
    "    preprocess_weibo_text,\n",
    "    is_valid_for_annotation,\n",
    ")\n",
    "\n",
    "# LLM 配置（示例；请按实际修改）\n",
    "BASE_URL = 'http://10.13.12.164:7890/v1'\n",
    "API_KEY = 'abc123'\n",
    "MODEL_NAME = 'Qwen/Qwen3-8B'\n",
    "\n",
    "# 数据路径\n",
    "DATA_PATH = ROOT / 'dataset/Topic_data/#新冠后遗症#_filtered.csv'\n",
    "\n",
    "# 输出路径：本 notebook 默认输出到 intermediate（演示/临时文件）\n",
    "ANNOT_PATH = ROOT / 'outputs/annotations/intermediate/annotated_sample.jsonl'\n",
    "ANNOT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 主数据（正式分析以此为准）\n",
    "MASTER_PATH = ROOT / 'outputs/annotations/master/long_covid_annotations_master.jsonl'\n",
    "\n",
    "# 绘图输出\n",
    "FIG_DIR = ROOT / 'outputs/figs'\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 抽样设置：默认只跑小样本用于验证连通性\n",
    "SAMPLE_SIZE = 200  # 设为 None 或更大可扩大规模（不建议在 notebook 里直接全量跑）\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# 读取数据\n",
    "df = load_topic_dataset(DATA_PATH)\n",
    "\n",
    "# 初始化标注器\n",
    "ann = LLMAnnotator(\n",
    "    provider='openai',\n",
    "    api_key=API_KEY,\n",
    "    model=MODEL_NAME,\n",
    "    base_url=BASE_URL,\n",
    ")\n",
    "\n",
    "# 提示：master 现状（若存在）\n",
    "if MASTER_PATH.exists():\n",
    "    n_master = sum(1 for _ in MASTER_PATH.open('r', encoding='utf-8'))\n",
    "    print(f'master 标注文件存在: {MASTER_PATH} (rows={n_master})')\n",
    "else:\n",
    "    print(f'master 标注文件不存在: {MASTER_PATH} (本 notebook 仅会生成演示样本 {ANNOT_PATH.name})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 加载数据概览\n",
    "print('rows:', len(df))\n",
    "print(df.head())\n",
    "\n",
    "# 2) 预处理：清洗文本、过滤无效样本\n",
    "#    这里保留 mid 以便追溯；clean 文本用于送入 LLM\n",
    "required_cols = {'mid', 'content'}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f'dataset 缺少必要字段: {missing}')\n",
    "\n",
    "raw_df = df[['mid', 'content']].dropna()\n",
    "print(f'原始文本数: {len(raw_df)}')\n",
    "\n",
    "preprocessed = []  # (mid, original_text, clean_text)\n",
    "for mid, orig in raw_df.itertuples(index=False):\n",
    "    clean = preprocess_weibo_text(orig, max_length=500)\n",
    "    if is_valid_for_annotation(clean, min_length=5):\n",
    "        preprocessed.append((str(mid), orig, clean))\n",
    "\n",
    "print(f'有效文本数: {len(preprocessed)}')\n",
    "\n",
    "# 3) 抽样（默认小样本）\n",
    "if SAMPLE_SIZE is not None and len(preprocessed) > SAMPLE_SIZE:\n",
    "    preprocessed = random.sample(preprocessed, SAMPLE_SIZE)\n",
    "print(f'本次标注样本数: {len(preprocessed)} (SAMPLE_SIZE={SAMPLE_SIZE})')\n",
    "\n",
    "# 4) 展示预处理效果\n",
    "print('\n",
    "--- 预处理效果示例 ---')\n",
    "for i, (mid, orig, clean) in enumerate(preprocessed[:3]):\n",
    "    print(f'\n",
    "[样本 {i+1}] mid={mid}')\n",
    "    print(f'原文: {orig[:100]}...')\n",
    "    print(f'清洗后: {clean[:100]}...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 逐条调用 LLM 标注（使用清洗后的文本；保存 mid/原文/清洗后文本）\n",
    "results = []\n",
    "with ANNOT_PATH.open('w', encoding='utf-8') as f:\n",
    "    for mid, orig, clean in tqdm(preprocessed, desc='annotating'):\n",
    "        res = ann.annotate(clean, max_tokens=1024)\n",
    "\n",
    "        result_dict = res.to_dict()\n",
    "        result_dict['mid'] = mid\n",
    "        result_dict['original_text'] = orig\n",
    "        result_dict['content'] = clean\n",
    "\n",
    "        results.append(res)\n",
    "        f.write(json.dumps(result_dict, ensure_ascii=False) + '\n",
    "')\n",
    "\n",
    "print('done, saved to', ANNOT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 汇总统计（优先使用 master；否则使用本次演示样本）\n",
    "import pandas as pd\n",
    "\n",
    "STATS_PATH = MASTER_PATH if MASTER_PATH.exists() else ANNOT_PATH\n",
    "print('统计来源:', STATS_PATH)\n",
    "\n",
    "df_ann = pd.read_json(STATS_PATH, lines=True)\n",
    "print('rows:', len(df_ann))\n",
    "print(df_ann.head())\n",
    "\n",
    "required = {'emotion_class', 'risk_class'}\n",
    "missing = required - set(df_ann.columns)\n",
    "if missing:\n",
    "    print('WARNING: 缺少字段:', missing)\n",
    "\n",
    "print('\n",
    "=== 标注结果统计 ===')\n",
    "if 'emotion_class' in df_ann.columns:\n",
    "    print('\n",
    "情绪分布:')\n",
    "    print(df_ann['emotion_class'].value_counts(normalize=True))\n",
    "if 'risk_class' in df_ann.columns:\n",
    "    print('\n",
    "风险分布:')\n",
    "    print(df_ann['risk_class'].value_counts(normalize=True))\n",
    "\n",
    "if {'emotion_class', 'risk_class'} <= set(df_ann.columns):\n",
    "    print('\n",
    "=== 情绪 × 风险 交叉表 ===')\n",
    "    print(pd.crosstab(df_ann['emotion_class'], df_ann['risk_class'], normalize='all').round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Figures saved to', FIG_DIR)\n",
    "print('Sample annotations saved to', ANNOT_PATH)\n",
    "print('Master annotations (reference) at', MASTER_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 兼容单独运行：若未定义 ROOT/MASTER_PATH/ANNOT_PATH，则回退到 notebooks/..\n",
    "if 'ROOT' not in globals():\n",
    "    ROOT = Path('..').resolve()\n",
    "if 'MASTER_PATH' not in globals():\n",
    "    MASTER_PATH = ROOT / 'outputs/annotations/master/long_covid_annotations_master.jsonl'\n",
    "if 'ANNOT_PATH' not in globals():\n",
    "    ANNOT_PATH = ROOT / 'outputs/annotations/intermediate/annotated_sample.jsonl'\n",
    "\n",
    "FIG_DIR = ROOT / 'outputs/figs'\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STATS_PATH = MASTER_PATH if MASTER_PATH.exists() else ANNOT_PATH\n",
    "source_tag = 'master' if STATS_PATH == MASTER_PATH else 'sample'\n",
    "\n",
    "# 读取标注结果\n",
    "df_ann = pd.read_json(STATS_PATH, lines=True)\n",
    "\n",
    "# 情绪分布\n",
    "fig, ax = plt.subplots()\n",
    "if 'emotion_class' in df_ann.columns:\n",
    "    df_ann['emotion_class'].value_counts().reindex(['H', 'M', 'L']).plot(\n",
    "        kind='bar',\n",
    "        ax=ax,\n",
    "        color=['#d62728', '#1f77b4', '#2ca02c'],\n",
    "    )\n",
    "ax.set_title(f'Emotion distribution ({source_tag})')\n",
    "fig.tight_layout()\n",
    "fig.savefig(FIG_DIR / f'fig5_emotion_dist_{source_tag}.png', dpi=200)\n",
    "\n",
    "# 风险分布\n",
    "fig, ax = plt.subplots()\n",
    "if 'risk_class' in df_ann.columns:\n",
    "    df_ann['risk_class'].value_counts().reindex(['risk', 'norisk']).plot(\n",
    "        kind='bar',\n",
    "        ax=ax,\n",
    "        color=['#d62728', '#1f77b4'],\n",
    "    )\n",
    "ax.set_title(f'Risk distribution ({source_tag})')\n",
    "fig.tight_layout()\n",
    "fig.savefig(FIG_DIR / f'fig5_risk_dist_{source_tag}.png', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print('统计来源:', STATS_PATH)\n",
    "print('Figures saved to', FIG_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}